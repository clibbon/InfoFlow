{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "This is a study of how multiple entities can successfully gather and manage \"information\". In this case, information is just a set of random integers (I'll call these **facts**) drawn from a distribution that makes low numbers more likely (common knowledge), and high numbers rarer (little known pieces of information). \n",
    "\n",
    "We have a pool of entities, who are \"working\". To do their work they need to find particular facts. In the first instance there is only one way for the entities to find facts, that is to have them mine for them - equivalent to desk research.\n",
    "\n",
    "First lets pick an appropriate distribution for **facts** so some numbers are more common that others. I'm a big fan of the Beta distribution, and picked some values using [this app](https://homepage.divms.uiowa.edu/~mbognar/applets/beta.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0.8\n",
    "b = 2\n",
    "n_facts = 100\n",
    "facts = (n_facts * np.random.beta(a,b, (1000,))).astype(int)\n",
    "plt.hist(facts, bins=99, range=(0,n_facts-1))\n",
    "ax = plt.gca()\n",
    "ax.set_title(f\"Frequency of facts generated using a Beta distribution with a={a} and b={b}\");\n",
    "ax.set_ylabel(\"count\")\n",
    "ax.set_xlabel(\"fact id\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define the entities. Lets make them simple classes so they can have a state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Worker:\n",
    "    \"\"\"Abstract superclass for workers\"\"\"\n",
    "    known_facts: set[int]\n",
    "    target_fact: int|None\n",
    "    n_facts: int\n",
    "\n",
    "\n",
    "    def __init__(self, n_facts, known_facts) -> None:\n",
    "        self.n_facts = n_facts\n",
    "        self.known_facts = known_facts\n",
    "        self.target_fact = None\n",
    "\n",
    "    def act(self) -> None:\n",
    "        pass\n",
    "\n",
    "    def update(self) -> bool:\n",
    "        \"\"\"Returns true if work done (a needed fact is found), else false\"\"\"\n",
    "        if self.target_fact in self.known_facts:\n",
    "            self.generate_new_target_fact()\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def generate_new_target_fact(self) -> None:\n",
    "        self.target_fact = random.randint(0, n_facts-1)\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        return f\"Known facts: {self.known_facts}, target: {self.target_fact}\"\n",
    "    \n",
    "class Researcher(Worker):\n",
    "    \"\"\"Worker who only research facts\"\"\"\n",
    "    def __init__(self, n_facts, known_facts) -> None:\n",
    "        super().__init__(n_facts, known_facts)\n",
    "        self.generate_new_target_fact()\n",
    "\n",
    "    def do_research(self):\n",
    "        new_fact = int(self.n_facts * random.betavariate(a, b))\n",
    "        self.known_facts.add(new_fact)\n",
    "\n",
    "    def act(self) -> None:\n",
    "        self.do_research()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_WORKERS = 100\n",
    "N_STEPS = 50000\n",
    "workers = [Researcher(n_facts=n_facts, known_facts=set()) for _ in range(N_WORKERS)]\n",
    "\n",
    "n_successes = []\n",
    "\n",
    "for _ in range(N_STEPS):\n",
    "    for worker in workers:\n",
    "        worker.act()\n",
    "\n",
    "    n_successes_this_step = 0\n",
    "    for worker in workers:\n",
    "        n_successes_this_step += worker.update()\n",
    "    n_successes.append(n_successes_this_step/N_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(n_successes)\n",
    "ax = plt.gca()\n",
    "ax.set_title(\"Rate of work per worker over time\")\n",
    "ax.set_ylabel(\"Average units of work per worker\")\n",
    "ax.set_xlabel(\"Ticks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot shows what we expect - work is initially slow as people start off not knowing anything, but as they accumulate knowledge the work rate increases up to the theoretical maxima of 1 unit per worker. Lets assume that 50,000 ticks would be a very long time, and you would be very lucky to have such experienced staff on your books.\n",
    "\n",
    "This also makes a second important assumption, that workers have perfect memories! What does this look like if we make our academics forgetful? Let's start with a forget rate of on average 1 fact per 50 ticks by checking if a random number between 0 and 1 is <0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ForgetfulResearcher(Researcher):\n",
    "    \"\"\"Worker who only research facts\"\"\"\n",
    "\n",
    "    forget_rate: int\n",
    "\n",
    "    def __init__(self, n_facts, known_facts, forget_rate) -> None:\n",
    "        super().__init__(n_facts, known_facts)\n",
    "        self.generate_new_target_fact()\n",
    "        self.forget_rate = forget_rate\n",
    "\n",
    "    def forget(self):\n",
    "        if len(self.known_facts) > 0:\n",
    "            if random.random() < self.forget_rate:\n",
    "                self.known_facts.pop()\n",
    "\n",
    "\n",
    "    def act(self) -> None:\n",
    "        self.forget()\n",
    "        self.do_research()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(workers, n_steps):\n",
    "    n_workers = len(workers)\n",
    "\n",
    "    n_successes = []\n",
    "\n",
    "    for _ in range(n_steps):\n",
    "        for worker in workers:\n",
    "            worker.act()\n",
    "\n",
    "        n_successes_this_step = 0\n",
    "        for worker in workers:\n",
    "            n_successes_this_step += worker.update()\n",
    "        n_successes.append(n_successes_this_step/n_workers)\n",
    "    \n",
    "    return n_successes\n",
    "\n",
    "def plot_experiment(n_successes):\n",
    "    plt.plot(n_successes)\n",
    "    ax = plt.gca()\n",
    "    ax.set_title(\"Rate of work per worker over time\")\n",
    "    ax.set_ylabel(\"Average units of work per worker\")\n",
    "    ax.set_xlabel(\"Ticks\")\n",
    "\n",
    "\n",
    "FORGET_RATE = 0.01\n",
    "N_WORKERS = 100\n",
    "N_STEPS = 50000\n",
    "workers = [ForgetfulResearcher(n_facts=n_facts, known_facts=set(), forget_rate=FORGET_RATE) for _ in range(N_WORKERS)]\n",
    "n_successes_forgetful = run_experiment(workers, N_STEPS)\n",
    "plot_experiment(n_successes_forgetful)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well now that is way more interesting than I thought! I'd simply assumed that we'd see a shape similar to the perfect researcher, but stabilising at a lower value as people forget facts as quickly as they can research them. In fact we see people working away until slowly more and more of them get stuck searching for a particularly hard to find fact, and while doing that forgetting everything else they know! We see a couple of cycles of everyone experiencing this effect roughly together before things spread out and we see the average work stabilising. \n",
    "\n",
    "**I am pretty suspicious of this result but can see any obvious bugs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FORGET_RATE = 0.005\n",
    "N_WORKERS = 100\n",
    "N_STEPS = 50000\n",
    "workers = [ForgetfulResearcher(n_facts=n_facts, known_facts=set(), forget_rate=FORGET_RATE) for _ in range(N_WORKERS)]\n",
    "n_successes_forgetful = run_experiment(workers, N_STEPS)\n",
    "plot_experiment(n_successes_forgetful)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly if I lower `FORGET_RATE` to 0.005, we see the same pattern but smoother. This is very odd and quite interesting, but not my goal for now which is to start exploring the benefits of sharing knowledge and centralised knowledge bases.\n",
    "\n",
    "I also want to see if the pattern does indeed stabilise, so lets run for many steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FORGET_RATE = 0.01\n",
    "N_WORKERS = 100\n",
    "N_STEPS = 500000\n",
    "workers = [ForgetfulResearcher(n_facts=n_facts, known_facts=set(), forget_rate=FORGET_RATE) for _ in range(N_WORKERS)]\n",
    "n_successes_forgetful = run_experiment(workers, N_STEPS)\n",
    "plot_experiment(n_successes_forgetful)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK its very difficult to see what is going on there, so lets smoothen things to look at how the average changes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_SIZE = 3001\n",
    "smooth_n_successes_forgetful = np.convolve(n_successes_forgetful, np.ones(WINDOW_SIZE), 'valid') / WINDOW_SIZE\n",
    "\n",
    "ax = plt.subplot()\n",
    "ax.plot(smooth_n_successes_forgetful)\n",
    "ax.set_title(\"Rate of work per worker over time\")\n",
    "ax.set_ylabel(\"Average units of work per worker\")\n",
    "ax.set_xlabel(\"Ticks\")\n",
    "ax.axvline(75000, linestyle=\":\", color=\"k\")\n",
    "ax.text(x=77000, y=0.08, s=\"Settles into constant rate\", rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly we see a few cycles of work and learn, getting stuck and forget, work, getting stuck, where everyone is a little aligned before a more chaotic pattern emerges after the first 75K steps where I believe workers are still getting stuck looking for facts, but their are no longer syncronised.\n",
    "\n",
    "Lets look now into how effective it can be to ask colleagues for help. We'll now let workers ask other workers, and if their target fact is in a colleagues known facts, work is done. This requires a new worker class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SociableResearcer(ForgetfulResearcher):\n",
    "    \"\"\"Worker who asks colleages for help occasionally\"\"\"\n",
    "\n",
    "    socialise_rate: int\n",
    "\n",
    "    def __init__(self, n_facts, known_facts, forget_rate, socialise_rate) -> None:\n",
    "        super().__init__(n_facts, known_facts, forget_rate)\n",
    "        self.socialise_rate = socialise_rate\n",
    "\n",
    "    def set_colleagues(self, colleagues):\n",
    "        \"\"\"Has to be done outside of the constructor, as for convenience this list usually includes this reasearcher,\n",
    "        and it can be tricky to create a set of researchers who are all aware of eachother.\"\"\"\n",
    "        self.colleageus = colleagues\n",
    "        self.n_colleagues = len(colleagues)\n",
    "\n",
    "    def ask_colleague(self):\n",
    "        random_idx = random.randint(0,self.n_colleagues-1)\n",
    "        colleagues_facts = self.colleageus[random_idx].known_facts\n",
    "\n",
    "        if self.target_fact in colleagues_facts:\n",
    "            self.known_facts.add(self.target_fact)\n",
    "\n",
    "    def act(self) -> None:\n",
    "        self.forget()\n",
    "        if random.random() < self.socialise_rate:\n",
    "            self.ask_colleague()\n",
    "        else:\n",
    "            self.do_research()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_STEPS = 50000\n",
    "workers = [SociableResearcer(n_facts=n_facts, \n",
    "                             known_facts=set(), \n",
    "                             forget_rate=FORGET_RATE,\n",
    "                             socialise_rate=0.1) for _ in range(N_WORKERS)]\n",
    "for worker in workers:\n",
    "    worker.set_colleagues(workers)\n",
    "\n",
    "n_successes_sociable = run_experiment(workers, N_STEPS)\n",
    "plot_experiment(n_successes_sociable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The power of asking colleagues! The work rate ramps up very quickly, and hovers around the maximum. This is a bit generous however, as currently asking a colleagues doesn't impact the person being asked. To make this more realistic, lets assume that being asked takes that colleague out of the pool of people who can potentially do work. \n",
    "\n",
    "This means we need to have a potentially complex system of going through workers in order, seeing who they would like to ask each time, and then taking that person out of the pool, which means a little re-write to the way we run the experiment code in a way that breaks the existing act function. I'm not sure on the best way to handle such a breaking change, other than to write a new class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SociableResearcer_v2(ForgetfulResearcher):\n",
    "    \"\"\"Worker who asks colleages for help occasionally\"\"\"\n",
    "\n",
    "    socialise_rate: int\n",
    "\n",
    "    def __init__(self, n_facts, known_facts, forget_rate, socialise_rate) -> None:\n",
    "        super().__init__(n_facts, known_facts, forget_rate)\n",
    "        self.socialise_rate = socialise_rate\n",
    "\n",
    "    def set_colleagues(self, colleagues):\n",
    "        \"\"\"Has to be done outside of the constructor, as for convenience this list usually includes this reasearcher,\n",
    "        and it can be tricky to create a set of researchers who are all aware of eachother.\"\"\"\n",
    "        self.colleageus = colleagues\n",
    "        self.n_colleagues = len(colleagues)\n",
    "\n",
    "    def ask_colleague(self, free_resource_ids):\n",
    "        chosen_idx = random.choice(free_resource_ids)\n",
    "        free_resource_ids.remove(chosen_idx)\n",
    "        colleagues_facts = self.colleageus[chosen_idx].known_facts\n",
    "\n",
    "        if self.target_fact in colleagues_facts:\n",
    "            self.known_facts.add(self.target_fact)\n",
    "\n",
    "    def act(self, free_resource_ids) -> None:\n",
    "        self.forget()\n",
    "        at_least_one_free_colleague = len(free_resource_ids) > 0\n",
    "        feeling_sociable = random.random() < self.socialise_rate\n",
    "        if at_least_one_free_colleague & feeling_sociable:\n",
    "            self.ask_colleague(free_resource_ids)\n",
    "        else:\n",
    "            self.do_research()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment_v2(workers, n_steps):\n",
    "    n_workers = len(workers)\n",
    "\n",
    "    n_successes = []\n",
    "\n",
    "    for _ in range(n_steps): \n",
    "        free_resources = [i for i in range(0, n_workers)]\n",
    "        random.shuffle(free_resources)  # Act in a random order to give everyone a chance\n",
    "\n",
    "\n",
    "        for idx in range(n_workers):\n",
    "            if idx in free_resources:\n",
    "                free_resources.remove(idx)\n",
    "                workers[idx].act(free_resources)\n",
    "\n",
    "        n_successes_this_step = 0\n",
    "\n",
    "        for worker in workers:\n",
    "            n_successes_this_step += worker.update()\n",
    "        n_successes.append(n_successes_this_step/n_workers)\n",
    "    \n",
    "    return n_successes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_STEPS = 10000\n",
    "SOCIALISE_RATE = 0.1\n",
    "workers = [SociableResearcer_v2(n_facts=n_facts, \n",
    "                             known_facts=set(), \n",
    "                             forget_rate=FORGET_RATE,\n",
    "                             socialise_rate=0.1) for _ in range(N_WORKERS)]\n",
    "for worker in workers:\n",
    "    worker.set_colleagues(workers)\n",
    "\n",
    "n_successes_sociable_v2 = run_experiment_v2(workers, N_STEPS)\n",
    "plot_experiment(n_successes_sociable_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.subplot()   \n",
    "ax.plot(n_successes_sociable[:10000])\n",
    "ax.plot(n_successes_sociable_v2, \"g\")\n",
    "ax.plot(n_successes_forgetful[:10000], \"r\")\n",
    "ax.set_title(\"Rate of work per worker over time\")\n",
    "ax.set_ylabel(\"Average units of work per worker\")\n",
    "ax.set_xlabel(\"Ticks\")\n",
    "ax.legend(['Sociable-V1', 'Sociable-V2', \"Forgetful\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see now the impact of being sociable, even when it means you take someone else out of the equation temporarily! You can imagine a situation where if one spends too much time asking around then nothing actually gets done. What happens when the socialise rate is turned up to abominable levels?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_STEPS = 10000\n",
    "SOCIALISE_RATE = 0.9\n",
    "workers = [SociableResearcer_v2(n_facts=n_facts, \n",
    "                             known_facts=set(), \n",
    "                             forget_rate=FORGET_RATE,\n",
    "                             socialise_rate=SOCIALISE_RATE) for _ in range(N_WORKERS)]\n",
    "for worker in workers:\n",
    "    worker.set_colleagues(workers)\n",
    "\n",
    "n_successes_sociable_v3 = run_experiment_v2(workers, N_STEPS)\n",
    "plot_experiment(n_successes_sociable_v3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again this was not the graph I was expecting - this is turning out to be a very interesting system with some hard to predict behaviours. If researchers spend 90% of their time asking eachother rather than looking for facts they spend a very long time getting nothing done, however once they discover a few facts the speed of progress is very rapid. It seems that in cases like this the whole group is getting stuck looking for a single fact, creating bottlenecks. This isn't really realistic, as it isn't likely that a whole organisation will all be working on the same thing at the same time (and spending most of their time asking eachother about it).\n",
    "\n",
    "There is one final mechanism I'd like to introduce into this system - the centralised knowledge repository. Workers can spend some time contributing to this repository, giving them a mechanism to push knowledge to a central database. To represent the fact it takes much more time to contribute something to a repository than it does to read, I'll assign a contribution probability to things (so I don't have to modify the tick system I currently use which doesn't allow for actions that take more than one tick!). They can then also query this database, in addition to being able to ask random colleagues.\n",
    "\n",
    "Since we've got quite a few settings now I'll group them together into a dataclass to simplify things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class DatabaseResearcherSettings:\n",
    "    forget_rate: float\n",
    "    socialise_rate: float\n",
    "    contribution_success_rate: float\n",
    "    database_query_rate: float\n",
    "    database_write_rate: float    \n",
    "\n",
    "class DatabaseResearcher(SociableResearcer_v2):\n",
    "    \"\"\"Worker who have access to, and contribute to, a central database, in addition to asking colleagues.\"\"\"\n",
    "\n",
    "    contribution_success_rate: float\n",
    "    socialise_threshold: float\n",
    "    database_query_threshold: float\n",
    "    database_write_threshold: float\n",
    "\n",
    "    def __init__(self, n_facts, known_facts, settings: DatabaseResearcherSettings, database: set) -> None:\n",
    "        super().__init__(n_facts, known_facts, settings.forget_rate, settings.socialise_rate)\n",
    "        self.validate_settings(settings)\n",
    "        self.init_thresholds(settings)\n",
    "\n",
    "        self.contribution_success_rate = settings.contribution_success_rate\n",
    "        self.database = database\n",
    "\n",
    "    def validate_settings(self, settings: DatabaseResearcherSettings):\n",
    "        \"\"\"Make sure the event probabilities add to less than 1, or some will never occur.\"\"\"\n",
    "        assert (settings.socialise_rate + settings.database_query_rate + settings.database_write_rate) < 1., \"Event rates (socialise_rate, query_rate, write_rate) cannot total more than 1.\"\n",
    "\n",
    "    def init_thresholds(self, settings: DatabaseResearcherSettings):\n",
    "        \"\"\"Initialise thresholds for actions based on the probability of each action occuring.\"\"\"\n",
    "        self.socialise_threshold = settings.socialise_rate\n",
    "        self.database_query_threshold = self.socialise_threshold + settings.database_query_rate\n",
    "        self.database_write_threshold = self.database_query_threshold + settings.database_write_rate\n",
    "\n",
    "    def query_database(self):\n",
    "        \"\"\"If the thing we're looking for is in the database, add it to our known facts\"\"\"\n",
    "        if self.target_fact in self.database:\n",
    "            self.known_facts.add(self.target_fact)\n",
    "            \n",
    "    def write_to_database(self):\n",
    "        chosen_fact = random.choice(list(self.known_facts))  # There must be a better way but I have no internet!\n",
    "        succeeds_at_writing = random.random() < self.contribution_success_rate\n",
    "        if succeeds_at_writing:\n",
    "            self.database.add(chosen_fact)\n",
    "\n",
    "    def act(self, free_resource_ids) -> None:\n",
    "        self.forget()\n",
    "        at_least_one_free_colleague = len(free_resource_ids) > 0\n",
    "        random_value = random.random()\n",
    "        feeling_sociable = random_value < self.socialise_threshold\n",
    "        knows_something = len(self.known_facts) > 0\n",
    "\n",
    "        if at_least_one_free_colleague & feeling_sociable:\n",
    "            self.ask_colleague(free_resource_ids)\n",
    "        elif random_value < self.database_query_threshold:\n",
    "            self.query_database()\n",
    "        elif knows_something & (random_value < self.database_write_threshold):\n",
    "            self.write_to_database()\n",
    "        else:\n",
    "            self.do_research()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_STEPS = 10000\n",
    "settings = DatabaseResearcherSettings(forget_rate=FORGET_RATE, \n",
    "                                      socialise_rate=0.1,\n",
    "                                      contribution_success_rate=0.1,\n",
    "                                      database_query_rate=0.1,\n",
    "                                      database_write_rate=0.05)\n",
    "shared_database=set()\n",
    "workers = [DatabaseResearcher(n_facts=n_facts, \n",
    "                             known_facts=set(), \n",
    "                             settings=settings,\n",
    "                             database=shared_database) for _ in range(N_WORKERS)]\n",
    "for worker in workers:\n",
    "    worker.set_colleagues(workers)\n",
    "\n",
    "n_successes_database = run_experiment_v2(workers, N_STEPS)\n",
    "plot_experiment(n_successes_database)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! So now we can run a few experiments to look at how each of these scenarios plays out as we modify the number of facts and the number of workers. To simply this I'll turn things into a number of workers and a ratio of facts per worker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing.pool import Pool\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ForgetfulResearcher_v2(ForgetfulResearcher):\n",
    "    \"\"\"An ugly creation to make the researcher handle the change to the act method in subclasses...\"\"\"\n",
    "\n",
    "    def __init__(self, n_facts, known_facts, forget_rate) -> None:\n",
    "        super().__init__(n_facts, known_facts, forget_rate)\n",
    "\n",
    "    def act(self, _) -> None:\n",
    "        self.forget()\n",
    "        self.do_research()\n",
    "\n",
    "def run_grand_experiment(settings: DatabaseResearcherSettings, n_workers: int, facts_per_worker: int, steps: int):\n",
    "    \n",
    "    n_facts = n_workers * facts_per_worker\n",
    "\n",
    "    # This section is nasty and I'm sorry. Fix when I can be bothered to make a proper factory.\n",
    "    worker_dict = dict()\n",
    "    worker_dict[\"Forgetful\"] = [ForgetfulResearcher_v2(n_facts=n_facts, \n",
    "                                                    known_facts=set(), \n",
    "                                                    forget_rate=settings.forget_rate) \n",
    "                                for _ in range(n_workers)]\n",
    "    \n",
    "    worker_dict[\"Sociable\"] = [SociableResearcer_v2(n_facts=n_facts, \n",
    "                                                    known_facts=set(), \n",
    "                                                    forget_rate=settings.forget_rate,\n",
    "                                                    socialise_rate=settings.socialise_rate) \n",
    "                                for _ in range(n_workers)]\n",
    "    for worker in worker_dict[\"Sociable\"]:\n",
    "        worker.set_colleagues(worker_dict[\"Sociable\"])\n",
    "\n",
    "    shared_database=set()\n",
    "    worker_dict[\"Datebaser\"] = [DatabaseResearcher(n_facts=n_facts, \n",
    "                                                   known_facts=set(), \n",
    "                                                   settings=settings,\n",
    "                                                   database=shared_database) \n",
    "                                for _ in range(n_workers)]\n",
    "    for worker in worker_dict[\"Datebaser\"]:\n",
    "        worker.set_colleagues(worker_dict[\"Datebaser\"])\n",
    "\n",
    "    results_dict = dict()\n",
    "    for researcher_type, researchers in worker_dict.items():\n",
    "        results_dict[researcher_type] = run_experiment_v2(researchers, steps)\n",
    "    return results_dict\n",
    "\n",
    "def plot_grand_experiment(results_dict, settings: DatabaseResearcherSettings):\n",
    "    ax = plt.subplot() \n",
    "    legend_labels = []\n",
    "\n",
    "    for researcher_type, results in results_dict.items():\n",
    "        ax.plot(results)\n",
    "        legend_labels.append(researcher_type)\n",
    "\n",
    "    ax.set_title(\"Rate of work per worker over time\")\n",
    "    ax.set_ylabel(\"Average units of work per worker\")\n",
    "    ax.set_xlabel(\"Ticks\")\n",
    "    ax.legend(legend_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = DatabaseResearcherSettings(forget_rate=FORGET_RATE, \n",
    "                                      socialise_rate=0.1,\n",
    "                                      contribution_success_rate=0.1,\n",
    "                                      database_query_rate=0.1,\n",
    "                                      database_write_rate=0.05)\n",
    "results = run_grand_experiment(settings, n_workers=10, facts_per_worker=100, steps=10_000)\n",
    "plot_grand_experiment(results, settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = DatabaseResearcherSettings(forget_rate=FORGET_RATE, \n",
    "                                      socialise_rate=0.1,\n",
    "                                      contribution_success_rate=0.05,\n",
    "                                      database_query_rate=0.1,\n",
    "                                      database_write_rate=0.1)\n",
    "results = run_grand_experiment(settings, n_workers=1000, facts_per_worker=1000, steps=10_000)\n",
    "plot_grand_experiment(results, settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = DatabaseResearcherSettings(forget_rate=FORGET_RATE, \n",
    "                                      socialise_rate=0.1,\n",
    "                                      contribution_success_rate=0.05,\n",
    "                                      database_query_rate=0.1,\n",
    "                                      database_write_rate=0.3)\n",
    "results = run_grand_experiment(settings, n_workers=1000, facts_per_worker=1000, steps=10_000)\n",
    "plot_grand_experiment(results, settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "optimal-rota",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
